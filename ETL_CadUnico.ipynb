{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando biblioteca para download dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baixando arquivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL do arquivo de dados\n",
    "url = 'https://aplicacoes.mds.gov.br/sagi/servicos/misocial?fq=anomes_s:2023*&wt=csv&omitHeader=true&fq=cadunico_tot_fam_i:{0%20TO%20*]&q=*&fl=ibge:codigo_ibge,anomes:anomes_s,cadunico_tot_fam:cadunico_tot_fam_i,cadunico_tot_pes:cadunico_tot_pes_i,cadunico_tot_fam_rpc_ate_meio_sm:cadunico_tot_fam_rpc_ate_meio_sm_i,cadunico_tot_pes_rpc_ate_meio_sm:cadunico_tot_pes_rpc_ate_meio_sm_i,cadunico_tot_fam_pob:cadunico_tot_fam_pob_i,cadunico_tot_pes_pob:cadunico_tot_pes_pob_i,cadunico_tot_fam_ext_pob:cadunico_tot_fam_ext_pob_i,cadunico_tot_pes_ext_pob:cadunico_tot_pes_ext_pob_i,cadunico_tot_fam_pob_e_ext_pob:cadunico_tot_fam_pob_e_ext_pob_i,cadunico_tot_pes_pob_e_ext_pob:cadunico_tot_pes_pob_e_ext_pob_i&rows=100000000&sort=anomes_s%20desc,%20codigo_ibge%20asc'\n",
    "file_path = 'cad_unico_renda.csv'\n",
    "\n",
    "# Fazer a requisição para baixar os dados\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verificar se a requisição foi bem-sucedida\n",
    "if response.status_code == 200:\n",
    "    # Salvar o conteúdo do arquivo localmente\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "#     # Carregar os dados no DataFrame\n",
    "#     df = pd.read_csv(file_path)\n",
    "    \n",
    "#     # Exibir as primeiras linhas do DataFrame\n",
    "#     print(df.head())\n",
    "else:\n",
    "    print(f\"Falha ao baixar os dados. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\python312\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --user pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando sessão spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Cria a sessão spark\n",
    "spark_session = SparkSession.builder.appName('spark') \\\n",
    "                                    .config(\"spark.driver.extraClassPath\", \"C:\\\\Users\\\\usuario\\\\Desktop\\\\ETL\\\\metabase\\\\postgresql-42.7.1.jar\") \\\n",
    "                                    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "                                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo arquivo csv e montando dataframe do spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------------+----------------+--------------------------------+--------------------------------+--------------------+--------------------+------------------------+------------------------+------------------------------+------------------------------+\n",
      "|  ibge|anomes|cadunico_tot_fam|cadunico_tot_pes|cadunico_tot_fam_rpc_ate_meio_sm|cadunico_tot_pes_rpc_ate_meio_sm|cadunico_tot_fam_pob|cadunico_tot_pes_pob|cadunico_tot_fam_ext_pob|cadunico_tot_pes_ext_pob|cadunico_tot_fam_pob_e_ext_pob|cadunico_tot_pes_pob_e_ext_pob|\n",
      "+------+------+----------------+----------------+--------------------------------+--------------------------------+--------------------+--------------------+------------------------+------------------------+------------------------------+------------------------------+\n",
      "|110001|202311|            4978|           12757|                            2886|                            8590|                 771|                2489|                     722|                    1965|                          1493|                          4454|\n",
      "|110002|202311|           19112|           44321|                           11575|                           30371|                2904|                8033|                    3368|                    8190|                          6272|                         16223|\n",
      "|110003|202311|             975|            2623|                             587|                            1805|                 169|                 521|                     102|                     290|                           271|                           811|\n",
      "|110004|202311|           18422|           42724|                           10005|                           26809|                2254|                6270|                    3270|                    8140|                          5524|                         14410|\n",
      "|110005|202311|            3239|            7813|                            1884|                            5295|                 573|                1594|                     505|                    1428|                          1078|                          3022|\n",
      "|110006|202311|            1870|            4889|                             982|                            2982|                 204|                 665|                     200|                     514|                           404|                          1179|\n",
      "|110007|202311|            1469|            3526|                             717|                            2082|                 179|                 524|                     124|                     356|                           303|                           880|\n",
      "|110008|202311|            4442|           10315|                            2959|                            8062|                 669|                1616|                    1477|                    4446|                          2146|                          6062|\n",
      "|110009|202311|            5733|           14822|                            3090|                            9605|                 676|                2192|                     794|                    2274|                          1470|                          4466|\n",
      "|110010|202311|           10468|           28388|                            7273|                           22569|                1994|                5494|                    3047|                   10774|                          5041|                         16268|\n",
      "|110011|202311|           10003|           24042|                            5902|                           16196|                1651|                4724|                    1226|                    3022|                          2877|                          7746|\n",
      "|110012|202311|           23589|           53941|                           13008|                           34533|                3455|                8990|                    3470|                    8649|                          6925|                         17639|\n",
      "|110013|202311|            7943|           20439|                            4698|                           13901|                1744|                5330|                     673|                    1972|                          2417|                          7302|\n",
      "|110014|202311|            4597|           11238|                            2621|                            7295|                 547|                1586|                     926|                    2500|                          1473|                          4086|\n",
      "|110015|202311|            7878|           18374|                            4290|                           11490|                1046|                3092|                    1251|                    2691|                          2297|                          5783|\n",
      "|110018|202311|            5972|           13926|                            2989|                            8040|                 723|                2011|                     694|                    1627|                          1417|                          3638|\n",
      "|110020|202311|          124716|          259169|                           82375|                          194091|               17580|               42869|                   41530|                   94777|                         59110|                        137646|\n",
      "|110025|202311|            6012|           13533|                            3428|                            8772|                 602|                1683|                    1590|                    3661|                          2192|                          5344|\n",
      "|110026|202311|             752|            1865|                             427|                            1238|                 103|                 319|                     114|                     329|                           217|                           648|\n",
      "|110028|202311|            9717|           22780|                            4876|                           13494|                1278|                3869|                     461|                    1113|                          1739|                          4982|\n",
      "+------+------+----------------+----------------+--------------------------------+--------------------------------+--------------------+--------------------+------------------------+------------------------+------------------------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark_session.read.options(header=\"true\", delimiter=\",\", encoding=\"ISO-8859-1\", inferSchema=True).csv('cad_unico_renda.csv')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando colunas relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining relevant columns\n",
    "relevant_columns=[\n",
    "    \"NR_TURNO\",\n",
    "    \"DS_ELEICAO\",\n",
    "    \"TP_ABRANGENCIA\",\n",
    "    \"SG_UF\",\n",
    "    \"NM_MUNICIPIO\",\n",
    "    \"NR_ZONA\",\n",
    "    \"DS_CARGO\",\n",
    "    \"NR_CANDIDATO\",\n",
    "    \"NM_CANDIDATO\",\n",
    "    \"NM_URNA_CANDIDATO\",\n",
    "    \"DS_SITUACAO_CANDIDATURA\",\n",
    "    \"NR_PARTIDO\",\n",
    "    \"SG_PARTIDO\",\n",
    "    \"NM_PARTIDO\",\n",
    "    \"NM_COLIGACAO\",\n",
    "    \"DS_COMPOSICAO_COLIGACAO\",\n",
    "    \"ST_VOTO_EM_TRANSITO\",\n",
    "    \"QT_VOTOS_NOMINAIS\",\n",
    "    \"NM_TIPO_DESTINACAO_VOTOS\",\n",
    "    \"QT_VOTOS_NOMINAIS_VALIDOS\",\n",
    "    \"DS_SIT_TOT_TURNO\"\n",
    "]\n",
    "\n",
    "# Selecting relevant columns\n",
    "selected_columns_df = df.select(relevant_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprimindo primeiras linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversão do dataframe para o modelo estrela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from typing import Dict, List\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "\n",
    "def get_columns_list_from_dimension(dimension: Dict[str, List[str]]):\n",
    "    return [col for cols in dimension for col in cols]\n",
    "\n",
    "def get_table_name_and_records(dataframe: DataFrame, dimension_table_name_and_columns: Dict[str, List[str]]) -> List[tuple[str, DataFrame]]:\n",
    "    dimensions = []\n",
    "\n",
    "    for dimension_table_name, dimension_columns in dimension_table_name_and_columns:\n",
    "        dimension_records = dataframe.select(*dimension_columns).distinct()\n",
    "        surrogate_key_column_name = f\"sk_{dimension_table_name.replace('dim_', '')}\"\n",
    "\n",
    "        # add unique and increasing id to dimension (but not consecutive)\n",
    "        unique_and_increasing_id = F.monotonically_increasing_id()\n",
    "        dimension_records = dimension_records.withColumn(\n",
    "            surrogate_key_column_name,\n",
    "            unique_and_increasing_id\n",
    "        )\n",
    "\n",
    "        dimension_table_in_tuple = (dimension_table_name, dimension_records)\n",
    "\n",
    "        dimensions.append(dimension_table_in_tuple)\n",
    "    \n",
    "    return dimensions\n",
    "\n",
    "\n",
    "def transform_spark_dataframe_into_star_schema(\n",
    "    original_dataframe: DataFrame,\n",
    "    fact_columns: List[str]  = [\"col1\", \"col2\"],\n",
    "    fact_table_name = \"tabela_fato\",\n",
    "    mapping_dimension_columns: Dict[str, List[str]] = {'dim1':[\"col3\", \"col4\"], \"dim2\":[\"col5\", \"col6\"]},\n",
    "):\n",
    "    dimension_columns_separated_by_dimension = mapping_dimension_columns.values()\n",
    "\n",
    "    dimension_columns = get_columns_list_from_dimension(dimension_columns_separated_by_dimension)\n",
    "\n",
    "    columns_from_fact_and_dimension = fact_columns + dimension_columns\n",
    "\n",
    "    original_dataframe = original_dataframe.select(*columns_from_fact_and_dimension)\n",
    "\n",
    "    dimension_table_name_and_columns = mapping_dimension_columns.items()\n",
    "\n",
    "    dimensions = get_table_name_and_records(original_dataframe, dimension_table_name_and_columns)\n",
    "\n",
    "    # Substitui as colunas de dimensão pelo respectivo SK na tabela fato\n",
    "    # ------------------------------------------------------------------\n",
    "    for table_name, records in dimensions:\n",
    "        # join the dimension dataframe to the original dataframe\n",
    "        dimension_columns_by_dimension_from_dataframe = [\n",
    "            original_dataframe[column] == records[column]\n",
    "            for column in mapping_dimension_columns[table_name]\n",
    "        ]\n",
    "        \n",
    "        original_dataframe = original_dataframe.join(\n",
    "            F.broadcast(records), \n",
    "            on=dimension_columns_by_dimension_from_dataframe,\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "    # drop the original columns\n",
    "    original_dataframe = original_dataframe.drop(*dimension_columns)\n",
    "\n",
    "    fact_table = (fact_table_name, original_dataframe)\n",
    "    \n",
    "    return dimensions + [fact_table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_schema = transform_spark_dataframe_into_star_schema(\n",
    "    selected_columns_df,\n",
    "    fact_columns=[\"QT_VOTOS_NOMINAIS_VALIDOS\", \"QT_VOTOS_NOMINAIS\"],\n",
    "    fact_table_name=\"tabela_fato\",\n",
    "    mapping_dimension_columns={\n",
    "        'dim_municipio': [\"SG_UF\", \"NM_MUNICIPIO\"],\n",
    "        'dim_cargo': [\"DS_CARGO\"],\n",
    "        'dim_ds_eleicao':[\"DS_ELEICAO\"],\n",
    "        'dim_partido':[\"SG_PARTIDO\",\"NM_PARTIDO\", \"NR_PARTIDO\"],\n",
    "        'dim_candidato':[\"NM_CANDIDATO\", \"NR_CANDIDATO\", \"NM_URNA_CANDIDATO\"],\n",
    "        'dim_turno':[\"NR_TURNO\"],\n",
    "        'dim_tp_agrangencia':[\"TP_ABRANGENCIA\"],\n",
    "        'dim_zona':[\"NR_ZONA\"],\n",
    "        'dim_situacao_candidatura':[\"DS_SITUACAO_CANDIDATURA\"],\n",
    "        'dim_coligacao':[\"NM_COLIGACAO\", \"DS_COMPOSICAO_COLIGACAO\"],\n",
    "        \"dim_voto_transito\":[\"ST_VOTO_EM_TRANSITO\"],\n",
    "        'dim_situacaof_turno':[\"DS_SIT_TOT_TURNO\"],\n",
    "        'dim_destinacao_voto':[\"NM_TIPO_DESTINACAO_VOTOS\"]\n",
    "    },   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando conexão com o banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname_or_ip = \"34.172.175.190\"\n",
    "port = \"443\"\n",
    "db = \"metabase\"\n",
    "user = \"star\"\n",
    "password = \"star\"\n",
    "\n",
    "db_url = \"jdbc:postgresql://\" + hostname_or_ip + \":\" + port + \"/\" + db\n",
    "\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\", \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transferindo modelo estrela para o banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in star_schema:\n",
    "    table_name,dataframe = item\n",
    "    print(f\"Writing {table_name} to Eleicoes DB\")\n",
    "    if table_name == \"dim_municipio\":\n",
    "        dataframe.write.jdbc(url=db_url, table=table_name, mode=\"overwrite\", properties=properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desalocando sessão do spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping spark session\n",
    "spark_session.stop()\n",
    "\n",
    "# Cleaning up files \n",
    "# Delete the directory and all its contents\n",
    "# import shutil\n",
    "\n",
    "# shutil.rmtree(workdir+'extracted/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
